# Action Plan: Fix anyclaude Stability Issues

## TL;DR

Your system has **truncation bugs** (not prompt size issues).

**3 fixes needed, 2-3 hours total:**

1. Fix stream draining (90% truncation reduction)
2. Add timeout protection (prevent stuck requests)
3. Add request logging (visibility)

Then it will be **stable and reliable**.

---

## The Problem (Simple Version)

**What's wrong**:

- Responses cut off mid-stream (truncation ~5-10%)
- Sometimes requests don't complete (no message_stop)
- Can't see what's happening (no logs)

**What's NOT wrong**:

- System prompt size (keep it all, you need context)
- Hardware latency (accept 10-20s startup, it's normal)
- Caching (already working, helps when it can)

**Why it's happening**:

- Stream not properly draining before close
- Message-stop event not guaranteed
- No visibility into failures

---

## The 3 Fixes

### FIX #1: Stream Draining (1 hour)

**Problem**: `res.end()` called before buffer fully flushed

**Solution**: Check if data is buffered, wait for drain event before closing

**Location**: `src/anthropic-proxy.ts` around line 1046 (close handler)

**Code**:

```typescript
close() {
  // ... cleanup code ...

  // Check if there's buffered data
  if (res.writableLength > 0) {
    // Wait for drain before closing
    res.once('drain', () => {
      setImmediate(() => res.end());
    });
    // Safety timeout
    setTimeout(() => {
      if (!res.writableEnded) res.end();
    }, 5000);
  } else {
    // No buffered data, safe to close
    setImmediate(() => res.end());
  }
}
```

**Expected**: 90% reduction in truncation

---

### FIX #2: Message-Stop Timeout (45 min)

**Problem**: Message-stop might not be sent if stream closes unexpectedly

**Solution**: Add timeout to force send message-stop after 60 seconds

**Location**: `src/convert-to-anthropic-stream.ts` around line 36

**Code**:

```typescript
// Add this after TransformStream is created:
const messageStopTimeout = setTimeout(() => {
  if (!messageStopSent) {
    debug(1, `[Stream] Forcing message_stop (timeout)`);
    controller.enqueue({ type: "message_stop" });
    messageStopSent = true;
  }
}, 60000);

// Clear timeout in flush():
flush(controller) {
  if (messageStopTimeout) clearTimeout(messageStopTimeout);
  // ... rest of flush code ...
}
```

**Expected**: Guaranteed request completion

---

### FIX #3: Request Logging (45 min)

**Problem**: Can't see what's happening when issues occur

**Solution**: Log all requests in JSONL format for analysis

**Location**: Create new file `src/request-logger.ts` and use in `anthropic-proxy.ts`

**Code** (simplified):

```typescript
// src/request-logger.ts
export function logRequest(body, provider, model) {
  const log = {
    timestamp: new Date().toISOString(),
    systemSize: body.system?.length || 0,
    toolCount: body.tools?.length || 0,
    messageCount: body.messages?.length || 0,
    streaming: body.stream,
    provider,
    model,
  };

  // Write to ~/.anyclaude/request-logs/*.jsonl
  const logFile = path.join(
    process.env.HOME,
    ".anyclaude",
    "request-logs",
    `${new Date().toISOString().split("T")[0]}.jsonl`
  );
  fs.appendFileSync(logFile, JSON.stringify(log) + "\n");
}
```

**Expected**: Full visibility for debugging

---

## Implementation Steps

### Step 1: Backup and branch

```bash
git checkout -b fix/stability-issues
```

### Step 2: Implement FIX #1 (stream draining)

- Edit `src/anthropic-proxy.ts` line ~1046
- Replace `close()` handler with enhanced version
- Test: `npm run build`

### Step 3: Implement FIX #2 (message-stop timeout)

- Edit `src/convert-to-anthropic-stream.ts` line ~36
- Add timeout protection
- Test: `npm run build`

### Step 4: Implement FIX #3 (request logging)

- Create `src/request-logger.ts`
- Update `src/anthropic-proxy.ts` to call logging
- Test: `npm run build`

### Step 5: Test everything

```bash
npm run build
npm test
# Should see: 75/75 tests pass

# Manual test:
ANYCLAUDE_DEBUG=2 anyclaude
# Type: "explain machine learning"
# Should see: Complete response, no truncation
# Check logs: cat ~/.anyclaude/request-logs/*.jsonl | jq .
```

---

## What Happens Now

### ‚úÖ Your System Will Be

- **Stable**: No truncation
- **Reliable**: Responses always complete
- **Observable**: Can see what's happening
- **Fast enough for local**: Accept the latency

### ‚ö†Ô∏è Your System Won't Be

- Faster than Anthropic API (hardware limit)
- Faster than cloud services (by design)
- Instant responses (Apple Silicon limitation)

But that's **fine** - you're trading speed for privacy and no API costs.

---

## Timeline

**If you implement today**:

- FIX #1: 1 hour
- FIX #2: 45 min
- FIX #3: 45 min
- Testing: 30 min
- **Total: 2.75 hours**

**Result**: Stable system by end of day

---

## Verification

After implementing, you should see:

‚úÖ **No truncation** in responses
‚úÖ **Message-stop always sent** (check logs)
‚úÖ **Complete responses** every time
‚úÖ **Request logs** showing what's happening
‚úÖ **Cache working** (check hit rate in logs)

If you still have issues:

1. Check request logs: `cat ~/.anyclaude/request-logs/*.jsonl | tail -10 | jq .`
2. Enable debug: `ANYCLAUDE_DEBUG=3 anyclaude`
3. Compare with LMStudio: `anyclaude --mode=lmstudio`

---

## Important Notes

‚ö†Ô∏è **DON'T reduce system prompt** - You need the full context
‚ö†Ô∏è **DON'T move guidance to .clinerules** - Claude needs it in system
‚ö†Ô∏è **DON'T try to make it as fast as Anthropic API** - Hardware limitation

‚úÖ **DO keep full documentation in system** - Better results
‚úÖ **DO accept 10-20s startup latency** - Normal for local hardware
‚úÖ **DO use it for deep work** - Where startup time doesn't matter

---

## Bottom Line

After these 3 fixes:

**You'll have**:

- ‚úÖ Stable Claude Code locally
- ‚úÖ Full context for good decisions
- ‚úÖ Privacy (no cloud)
- ‚úÖ No API costs
- ‚úÖ Works offline

**You won't have**:

- ‚ö†Ô∏è Cloud-speed performance
- ‚ö†Ô∏è Instant responses

**That's the deal for running locally, and it's a good one.**

Let's make it stable. üöÄ
