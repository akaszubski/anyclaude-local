{
  "model": "gpt-oss-20b",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant. Use the available tools to complete tasks."
    },
    {
      "role": "user",
      "content": "Please read the README.md file and tell me what this project does."
    },
    {
      "role": "assistant",
      "content": "",
      "tool_calls": [
        {
          "id": "call_0",
          "type": "function",
          "function": {
            "name": "Read",
            "arguments": "{\"file_path\": \"README.md\"}"
          }
        }
      ]
    },
    {
      "role": "tool",
      "tool_call_id": "call_0",
      "content": "# anyclaude\n\nTranslation layer for Claude Code that enables using local MLX models through the Anthropic API format. Intercepts Anthropic API calls and translates them to/from OpenAI Chat Completions format for MLX.\n\n## Features\n- Auto-launches MLX server with your configured model\n- Prompt caching for faster responses\n- Tool calling support\n- Streaming responses"
    }
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "Read",
        "description": "Read a file from the filesystem",
        "parameters": {
          "type": "object",
          "properties": {
            "file_path": {
              "type": "string",
              "description": "The path to the file to read"
            }
          },
          "required": ["file_path"]
        }
      }
    }
  ],
  "stream": false,
  "max_tokens": 1000
}
