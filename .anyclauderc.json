{
  "backend": "mlx",
  "debug": {
    "level": 3,
    "enableTraces": true,
    "enableStreamLogging": true
  },
  "backends": {
    "mlx": {
      "enabled": true,
      "port": 8081,
      "baseUrl": "http://localhost:8081/v1",
      "apiKey": "mlx",
      "model": "openai-gpt-oss-120b-MLX-6.5bit",
      "modelPath": "/Users/andrewkaszubski/Models/inferencerlabs/openai-gpt-oss-120b-MLX-6.5bit",
      "maxTokens": 131072,
      "serverScript": "scripts/mlx-server.py",
      "description": "OpenAI GPT OSS 120B (6.5-bit) - Largest model, best quality"
    },
    "lmstudio": {
      "enabled": true,
      "baseUrl": "http://localhost:1234/v1",
      "apiKey": "lm-studio",
      "model": "current-model",
      "compatibility": "legacy",
      "description": "Local LMStudio with openai-gpt-oss-20b (100+ tokens/sec, tool calling works)"
    },
    "claude": {
      "enabled": false,
      "description": "Real Anthropic API"
    },
    "openrouter": {
      "enabled": true,
      "baseUrl": "https://openrouter.ai/api/v1",
      "apiKey": "",
      "model": "qwen/qwen3-coder",
      "description": "OpenRouter - Qwen3 Coder 480B (3s, $0.22/$0.95, 262K) - Reliable tool calling, precise"
    }
  }
}
